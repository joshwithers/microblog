---
layout: post
microblog: true
guid: http://joshua.micro.blog/2023/08/10/tess-mcclure-in.html
post_id: 3487853
date: 2023-08-10T18:17:03+1100
lastmod: 2023-08-14T18:01:06+1100
type: post
categories:
- "Technology"
url: /2023/08/10/tess-mcclure-in.html
---
[Tess McClure in The Guardian](https://www.theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes) reports on Pak 'n' Save's mealbot:

> A New Zealand supermarket experimenting with using AI to generate meal plans has seen its app produce some unusual dishes – recommending customers recipes for deadly chlorine gas, “poison bread sandwiches” and mosquito-repellent roast potatoes.

> The app, created by supermarket chain Pak ‘n’ Save, was advertised as a way for customers to creatively use up leftovers during the cost of living crisis. It asks users to enter in various ingredients in their homes, and auto-generates a meal plan or recipe, along with cheery commentary. It initially drew attention on social media for some unappealing recipes, including an “oreo vegetable stir-fry”.

We're in the beautiful age of quality assurance in large language models. The giveaway is that the supermarket responds with:

> (we are) disappointed to see “a small minority have tried to use the tool inappropriately and not for its intended purpose

Instead of owning the issue and revealing that the whole thing is built on a house of cards and we're all just figuring this crap out.
